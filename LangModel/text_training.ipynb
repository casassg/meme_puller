{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_training.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "MBCx5DFVX6Hh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c0c694b-c450-4973-916c-0d2f363e7cc4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524776507204,
          "user_tz": 360,
          "elapsed": 1206,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import io\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Activation, Dense\n",
        "from keras.utils.data_utils import get_file\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JX6AClQ2X-Ye",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "N_GPU = 1 # you can experiment with more GPUs, it gets interesting with a high SEQUENCE_LEN\n",
        "SEQUENCE_LEN = 10\n",
        "# BATCH_SIZE = 512\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "# HIDDEN_LAYERS_DIM = 512\n",
        "HIDDEN_LAYERS_DIM = 100\n",
        "# LAYER_COUNT = 4\n",
        "LAYER_COUNT = 2\n",
        "DROPOUT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "odOxD7aZYA31",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "90b92636-2890-4f5e-fa35-c388b1cfcfdb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524778511450,
          "user_tz": 360,
          "elapsed": 224,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# loading the text\n",
        "path = get_file('memealsdjaljs.txt', origin='https://raw.githubusercontent.com/casassg/meme_puller/master/LangModel/cleaned_captions_4.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text_train = f.read().split()\n",
        "print('corpus length:', len(text_train))\n",
        "\n",
        "# generic vocabulary\n",
        "characters = sorted(list(set(text_train)))\n",
        "\n",
        "VOCABULARY_SIZE = len(characters)\n",
        "characters_to_ix = {c:i for i,c in enumerate(characters)}\n",
        "print(\"vocabulary len = %d\" % VOCABULARY_SIZE)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/casassg/meme_puller/master/LangModel/cleaned_captions_4.txt\n",
            "155648/149610 [===============================] - 0s 0us/step\n",
            "corpus length: 25010\n",
            "vocabulary len = 5068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m4hhsXhCYbHa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def describe_batch(X, y, samples=3):\n",
        "    \"\"\"Describe in a human-readable format some samples from a batch\"\"\"\n",
        "    for i in range(samples):\n",
        "        sentence = \"\"\n",
        "        for s in range(SEQUENCE_LEN):\n",
        "            sentence += characters[X[i,s,:].argmax()]\n",
        "            sentence +=' '\n",
        "        next_char = characters[y[i,:].argmax()]\n",
        "        \n",
        "        print(\"sample #%d: ...%s -> '%s'\" % (\n",
        "            i,\n",
        "            sentence[-20:],\n",
        "            next_char\n",
        "        ))\n",
        "\n",
        "def batch_generator(text, count):\n",
        "    \"\"\"Generate batches for training\"\"\"\n",
        "    while True: # keras wants that for reasons\n",
        "        for batch_ix in range(count):\n",
        "            X = np.zeros((BATCH_SIZE, SEQUENCE_LEN, VOCABULARY_SIZE))\n",
        "            y = np.zeros((BATCH_SIZE, VOCABULARY_SIZE))\n",
        "\n",
        "            batch_offset = BATCH_SIZE * batch_ix\n",
        "\n",
        "            for sample_ix in range(BATCH_SIZE):\n",
        "                sample_start = batch_offset + sample_ix\n",
        "                for s in range(SEQUENCE_LEN):\n",
        "                    X[sample_ix, s, characters_to_ix[text[sample_start+s]]] = 1\n",
        "                y[sample_ix, characters_to_ix[text[sample_start+s+1]]]=1\n",
        "\n",
        "            yield X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmnO22StYeHo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def build_model(gpu_count=1):\n",
        "    \"\"\"Build a Keras sequential model for training the char-rnn\"\"\"\n",
        "    model = Sequential()\n",
        "    for i in range(LAYER_COUNT):\n",
        "        model.add(\n",
        "            LSTM(\n",
        "                HIDDEN_LAYERS_DIM, \n",
        "                return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
        "                input_shape=(SEQUENCE_LEN, VOCABULARY_SIZE),\n",
        "            )\n",
        "        )\n",
        "        model.add(Dropout(DROPOUT))\n",
        "    \n",
        "    model.add(Dense(VOCABULARY_SIZE))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n87gicjxYg-t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "01a1b887-29eb-42c6-cd69-5423bc0189b4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524778520161,
          "user_tz": 360,
          "elapsed": 220,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "text_train_len = len(text_train)\n",
        "print(\"Total of %d characters\" % (text_train_len))\n",
        "\n",
        "for ix, (X,y) in enumerate(batch_generator(text_train, count=1)):\n",
        "    # describe some samples from the first batch\n",
        "    describe_batch(X, y, samples=5)\n",
        "    break"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total of 25010 characters\n",
            "sample #0: ...ove my country STOP  -> 'screw'\n",
            "sample #1: ... country STOP screw  -> 'science'\n",
            "sample #2: ... STOP screw science  -> 'man'\n",
            "sample #3: ...P screw science man  -> 'is'\n",
            "sample #4: ...crew science man is  -> 'back'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SnmfNSI1Yknv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25cb71ab-002f-4f9a-f069-2a345ee2443d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524778522034,
          "user_tz": 360,
          "elapsed": 730,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "training_model = build_model()\n",
        "\n",
        "train_batch_count = (text_train_len - SEQUENCE_LEN) // BATCH_SIZE\n",
        "print(\"training batch count: %d\" % train_batch_count)\n",
        "\n",
        "# checkpoint\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "filepath = \"./%d-gpu_BS-%d_%d-%s_dp%.2f_%dS_epoch{epoch:02d}-loss{loss:.4f}_weights\" % (\n",
        "    N_GPU,\n",
        "    BATCH_SIZE,\n",
        "    LAYER_COUNT,\n",
        "    HIDDEN_LAYERS_DIM,\n",
        "    DROPOUT,\n",
        "    SEQUENCE_LEN\n",
        ")\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath,\n",
        "    save_weights_only=True\n",
        ")\n",
        "#Â early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "callbacks_list = [checkpoint, early_stopping]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training batch count: 195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pwztsL-KYpL0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "edf7a3f1-8178-4536-cb33-8fc4c30add82"
      },
      "cell_type": "code",
      "source": [
        "history = training_model.fit_generator(\n",
        "    batch_generator(text_train, count=train_batch_count),\n",
        "    train_batch_count,\n",
        "    max_queue_size=1, # no more than one queued batch in RAM\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks_list,\n",
        "    initial_epoch=0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "195/195 [==============================] - 20s 101ms/step - loss: 7.0500\n",
            "Epoch 2/20\n",
            "  2/195 [..............................] - ETA: 18s - loss: 6.8076"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:526: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "195/195 [==============================] - 19s 99ms/step - loss: 6.6799\n",
            "Epoch 3/20\n",
            "152/195 [======================>.......] - ETA: 4s - loss: 6.7160"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GlBg9nmBy4O9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "41353de8-934d-4f59-a762-35810c14fd3b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524778383081,
          "user_tz": 360,
          "elapsed": 488,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "mypath = '.'\n",
        "onlyfiles = sorted([f for f in listdir(mypath) if isfile(join(mypath, f))])\n",
        "onlyfiles"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1-gpu_BS-128_2-100_dp0.20_10S_epoch01-loss6.8700_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch02-loss6.8409_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch03-loss6.8070_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch04-loss6.7537_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch05-loss6.7216_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch06-loss6.6689_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch07-loss6.6191_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch08-loss6.5649_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch09-loss6.5217_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch10-loss6.4731_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch11-loss6.4305_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch12-loss6.3732_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch13-loss6.3117_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch14-loss6.2465_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch15-loss6.1847_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch16-loss6.1334_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch17-loss6.0623_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch18-loss5.9966_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch19-loss5.9274_weights',\n",
              " '1-gpu_BS-128_2-100_dp0.20_10S_epoch20-loss5.8733_weights']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "kjKXri1cxlAO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('1-gpu_BS-128_2-100_dp0.20_10S_epoch20-loss5.8733_weights')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4AitWYoU2OvV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "141095b8-b4ff-4681-80e5-ff3f1524f4a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524778533434,
          "user_tz": 360,
          "elapsed": 235,
          "user": {
            "displayName": "Gerard Casas Saez",
            "photoUrl": "//lh3.googleusercontent.com/-RS9X48Y5KGk/AAAAAAAAAAI/AAAAAAAAdrE/rKWZNdp5dNk/s50-c-k-no/photo.jpg",
            "userId": "110796137064960208920"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "[os.remove(f) for f in onlyfiles]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}