{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Char-RNN Trump-like text generation - TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:15.895249Z",
     "start_time": "2018-04-27T18:12:13.626161Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "import io\n",
    "\n",
    "N_GPU = 1 # you can experiment with more GPUs, it gets interesting with a high SEQUENCE_LEN\n",
    "SEQUENCE_LEN = 10\n",
    "# BATCH_SIZE = 512\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "# HIDDEN_LAYERS_DIM = 512\n",
    "HIDDEN_LAYERS_DIM = 100\n",
    "# LAYER_COUNT = 4\n",
    "LAYER_COUNT = 2\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:16.161114Z",
     "start_time": "2018-04-27T18:12:15.897786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/casassg/meme_puller/master/LangModel/cleaned_captions_4.txt\n",
      "155648/149610 [===============================] - 0s 0us/step\n",
      "corpus length: 25010\n",
      "vocabulary len = 5068\n"
     ]
    }
   ],
   "source": [
    "# loading the text\n",
    "path = get_file('laskdhalhdla.txt', origin='https://raw.githubusercontent.com/casassg/meme_puller/master/LangModel/cleaned_captions_4.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text_train = f.read().split()\n",
    "print('corpus length:', len(text_train))\n",
    "\n",
    "# generic vocabulary\n",
    "characters = sorted(list(set(text_train)))\n",
    "\n",
    "VOCABULARY_SIZE = len(characters)\n",
    "characters_to_ix = {c:i for i,c in enumerate(characters)}\n",
    "print(\"vocabulary len = %d\" % VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:18.032767Z",
     "start_time": "2018-04-27T18:12:18.019078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'STOP' in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:19.623546Z",
     "start_time": "2018-04-27T18:12:19.211447Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = Sequential()\n",
    "for i in range(LAYER_COUNT):\n",
    "    test_model.add(\n",
    "            LSTM(\n",
    "                HIDDEN_LAYERS_DIM, \n",
    "                return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
    "                batch_input_shape=(1, 1, VOCABULARY_SIZE),\n",
    "                stateful=True\n",
    "            )\n",
    "        )\n",
    "test_model.add(Dense(VOCABULARY_SIZE))\n",
    "test_model.add(Activation('softmax'))\n",
    "test_model.compile(loss='categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:20.971086Z",
     "start_time": "2018-04-27T18:12:20.762659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model.load_weights(\n",
    "    \"./1-gpu_BS-128_2-100_dp0.20_10S_epoch60-loss4.2825_weights\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:22.047608Z",
     "start_time": "2018-04-27T18:12:21.970405Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array\"\"\"\n",
    "    # from fchollet/keras\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def predict_next_char(model, current_char, diversity=1.0):\n",
    "    \"\"\"Predict the next character from the current one\"\"\"\n",
    "    x = np.zeros((1, 1, VOCABULARY_SIZE))\n",
    "    x[:,:,characters_to_ix[current_char]] = 1\n",
    "    y = model.predict(x, batch_size=1)\n",
    "    next_char_ix = sample(y[0,:], temperature=diversity)\n",
    "    next_char = characters[next_char_ix]\n",
    "    return next_char\n",
    "\n",
    "def generate_text(model, seed=\"I\", count=140):\n",
    "    \"\"\"Generate characters from a given seed\"\"\"\n",
    "    model.reset_states()\n",
    "    \n",
    "    next_char = predict_next_char(model, seed)\n",
    "    current_char = seed\n",
    "\n",
    "    sys.stdout.write(\"[\"+seed+\"]\")\n",
    "    \n",
    "    for i in range(count - len(seed.split())):\n",
    "        next_char = predict_next_char(model, current_char, diversity=1.0)\n",
    "        if next_char == 'STOP':\n",
    "            break\n",
    "        current_char = next_char\n",
    "        sys.stdout.write(' ')\n",
    "        sys.stdout.write(next_char)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T18:12:47.706179Z",
     "start_time": "2018-04-27T18:12:47.537549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[comic_book] level want days\n",
      "\n",
      "[comic_book] rain april lul like games\n",
      "\n",
      "[comic_book] oscar i trap\n",
      "\n",
      "[comic_book] vegan the love comes the go\n",
      "\n",
      "[comic_book] stupid what hard day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    generate_text(\n",
    "        test_model,\n",
    "        seed=\"comic_book\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
